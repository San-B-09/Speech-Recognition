{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "    \n",
    "from glob import glob\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import stft\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class DatasetGenerator():\n",
    "    def __init__(self, label_set, \n",
    "                 sample_rate=16000):\n",
    "        \n",
    "        self.label_set = label_set\n",
    "        self.sample_rate = sample_rate\n",
    "            \n",
    "    # Covert string to numerical classes              \n",
    "    def text_to_labels(self, text):\n",
    "        return self.label_set.index(text)\n",
    "    \n",
    "    # Reverse translation of numerical classes back to characters\n",
    "    def labels_to_text(self, labels):\n",
    "        return self.label_set[labels]               \n",
    "        \n",
    "    def load_data(self, DIR):\n",
    "\n",
    "        # Get all paths inside DIR that ends with wav\n",
    "        wav_files = glob(os.path.join(DIR, '*/*wav'))\n",
    "        wav_files = [x.split(sep='\\\\')[1] + '/' + x.split(sep='\\\\')[2] for x in wav_files]\n",
    "        \n",
    "        # Loop over files to get samples\n",
    "        data = []\n",
    "        for e in wav_files:\n",
    "            \n",
    "            label, name = e.split('/')\n",
    "            if label in self.label_set:\n",
    "                label_id = self.text_to_labels(label)\n",
    "                fle = os.path.join(DIR, e)\n",
    "                \n",
    "                sample = (label, label_id, name, fle)\n",
    "                data.append(sample)\n",
    "            \n",
    "        # Data Frames with samples' labels and paths     \n",
    "        df = pd.DataFrame(data, columns = ['label', 'label_id', 'user_id', 'wav_file'])\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        return self.df\n",
    "\n",
    "    def apply_train_test_split(self, test_size, random_state):\n",
    "        \n",
    "        self.df_train, self.df_test = train_test_split(self.df, \n",
    "                                                       test_size=test_size,\n",
    "                                                       random_state=random_state)\n",
    "        \n",
    "    def apply_train_val_split(self, val_size, random_state):\n",
    "        \n",
    "        self.df_train, self.df_val = train_test_split(self.df_train, \n",
    "                                                      test_size=val_size, \n",
    "                                                      random_state=random_state)\n",
    "        \n",
    "    def read_wav_file(self, x):\n",
    "        # Read wavfile using scipy wavfile.read\n",
    "        _, wav = wavfile.read(x) \n",
    "        # Normalize\n",
    "        wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "            \n",
    "        return wav\n",
    "    \n",
    "    def process_wav_file(self, x, threshold_freq=5500, eps=1e-10):\n",
    "        # Read wav file to array\n",
    "        wav = self.read_wav_file(x)\n",
    "        # Sample rate\n",
    "        L = self.sample_rate\n",
    "        # If longer then randomly truncate\n",
    "        if len(wav) > L:\n",
    "            i = np.random.randint(0, len(wav) - L)\n",
    "            wav = wav[i:(i+L)]  \n",
    "        # If shorter then randomly add silence\n",
    "        elif len(wav) < L:\n",
    "            rem_len = L - len(wav)\n",
    "            silence_part = np.random.randint(-100,100,16000).astype(np.float32) / np.iinfo(np.int16).max\n",
    "            j = np.random.randint(0, rem_len)\n",
    "            silence_part_left  = silence_part[0:j]\n",
    "            silence_part_right = silence_part[j:rem_len]\n",
    "            wav = np.concatenate([silence_part_left, wav, silence_part_right])\n",
    "        # Create spectrogram using discrete FFT (change basis to frequencies)\n",
    "        freqs, times, spec = stft(wav, L, nperseg = 400, noverlap = 240, nfft = 512, padded = False, boundary = None)\n",
    "        # Cut high frequencies\n",
    "        if threshold_freq is not None:\n",
    "            spec = spec[freqs <= threshold_freq,:]\n",
    "            freqs = freqs[freqs <= threshold_freq]\n",
    "        # Log spectrogram\n",
    "        amp = np.log(np.abs(spec)+eps)\n",
    "    \n",
    "        return np.expand_dims(amp, axis=2) \n",
    "\n",
    "    def generator(self, batch_size, mode):\n",
    "        #print(type(self)) -> class daatset generator\n",
    "        while True:\n",
    "            # Depending on mode select DataFrame with paths\n",
    "            if mode == 'train':\n",
    "                df = self.df_train \n",
    "                ids = random.sample(range(df.shape[0]), df.shape[0])\n",
    "            elif mode == 'val':\n",
    "                df = self.df_val\n",
    "                ids = list(range(df.shape[0]))\n",
    "            elif mode == 'test':\n",
    "                df = self.df_test\n",
    "                ids = list(range(df.shape[0]))\n",
    "                #print(ids)\n",
    "            else:\n",
    "                raise ValueError('The mode should be either train, val or test.')\n",
    "                \n",
    "            # Create batches (for training data the batches are randomly permuted)\n",
    "            for start in range(0, len(ids), batch_size):\n",
    "                X_batch = []\n",
    "                if mode != 'test': \n",
    "                    y_batch = []\n",
    "                end = min(start + batch_size, len(ids))\n",
    "                i_batch = ids[start:end]\n",
    "                for i in i_batch:\n",
    "                    X_batch.append(self.process_wav_file(df.wav_file.values[i]))\n",
    "                    if mode != 'test':\n",
    "                        y_batch.append(df.label_id.values[i])\n",
    "                X_batch = np.array(X_batch)\n",
    "\n",
    "                if mode != 'test':\n",
    "                    y_batch = to_categorical(y_batch, num_classes = len(self.label_set))\n",
    "                    yield (X_batch, y_batch)\n",
    "                else:\n",
    "                    yield X_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"fig = plt.figure(figsize=(14, 8))\\nfor i, fn in enumerate(fns):\\n    wav = read_wav_file(DIR + fn)\\n    freqs, times, amp = log_spectrogram(wav)\\n    \\n    ax = fig.add_subplot(3,1,i+1)\\n    ax.imshow(amp, aspect='auto', origin='lower', \\n               extent=[times.min(), times.max(), freqs.min(), freqs.max()])\\n    ax.set_title('Spectrogram of ' + fn)\\n    ax.set_ylabel('Freqs in Hz')\\n    ax.set_xlabel('Seconds')\\nfig.tight_layout()\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "#import matplotlib.pyplot as plt\n",
    " \n",
    "DIR = 'D:/college/TRF/LEVEL-II/Task_3'\n",
    "'''fns = ['/bed/00f0204f_nohash_0.wav',\n",
    "       '/cat/00b01445_nohash_0.wav',\n",
    "       '/happy/0a2b400e_nohash_0.wav']'''\n",
    "SAMPLE_RATE = 16000\n",
    " \n",
    "def read_wav_file(x):\n",
    "    # Read wavfile using scipy wavfile.read\n",
    "    _, wav = wavfile.read(x) \n",
    "    # Normalize\n",
    "    wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "        \n",
    "    return wav\n",
    " \n",
    "'''fig = plt.figure(figsize=(14, 8))\n",
    "for i, fn in enumerate(fns):\n",
    "    wav = read_wav_file(DIR + fn)\n",
    " \n",
    "    ax = fig.add_subplot(3,1,i+1)\n",
    "    ax.set_title('Raw wave of ' + fn)\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.plot(np.linspace(0, SAMPLE_RATE/len(wav), SAMPLE_RATE), wav)\n",
    "fig.tight_layout()\n",
    "'''\n",
    "\n",
    "from scipy.signal import stft\n",
    " \n",
    "def log_spectrogram(wav):\n",
    "    freqs, times, spec = stft(wav, SAMPLE_RATE, nperseg = 400, noverlap = 240, nfft = 512, \n",
    "                              padded = False, boundary = None)\n",
    "    # Log spectrogram\n",
    "    amp = np.log(np.abs(spec)+1e-10)\n",
    "    \n",
    "    return freqs, times, amp\n",
    " \n",
    "'''fig = plt.figure(figsize=(14, 8))\n",
    "for i, fn in enumerate(fns):\n",
    "    wav = read_wav_file(DIR + fn)\n",
    "    freqs, times, amp = log_spectrogram(wav)\n",
    "    \n",
    "    ax = fig.add_subplot(3,1,i+1)\n",
    "    ax.imshow(amp, aspect='auto', origin='lower', \n",
    "               extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "    ax.set_title('Spectrogram of ' + fn)\n",
    "    ax.set_ylabel('Freqs in Hz')\n",
    "    ax.set_xlabel('Seconds')\n",
    "fig.tight_layout()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    " \n",
    "#from dataset import DatasetGenerator\n",
    " \n",
    "DIR = 'D:/college/TRF/LEVEL-II/Task_3'\n",
    " \n",
    "INPUT_SHAPE = (177,98,1)\n",
    "BATCH = 1\n",
    "EPOCHS = 15\n",
    " \n",
    "LABELS = 'bed bird on one'.split()\n",
    "NUM_CLASSES = len(LABELS)\n",
    "\n",
    "\n",
    "dsGen = DatasetGenerator(label_set=LABELS) \n",
    "# Load DataFrame with paths/labels \n",
    "df = dsGen.load_data(DIR)\n",
    "\n",
    "\n",
    "dsGen.apply_train_test_split(test_size=0.1, random_state=2018)\n",
    "dsGen.apply_train_val_split(val_size=0.1, random_state=2018)\n",
    "print(len(dsGen.df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 177, 98, 1)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv (Conv2D)         (None, 177, 98, 32)       320       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 89, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "block1_norm (BatchNormalizat (None, 89, 49, 32)        128       \n",
      "_________________________________________________________________\n",
      "block2_conv (Conv2D)         (None, 89, 49, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 45, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "block2_norm (BatchNormalizat (None, 45, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "block3_conv (Conv2D)         (None, 45, 25, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 23, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "block3_norm (BatchNormalizat (None, 23, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                612416    \n",
      "_________________________________________________________________\n",
      "dense_norm (BatchNormalizati (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "pred (Dense)                 (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 632,132\n",
      "Trainable params: 631,812\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "                          \n",
    "def deep(features_shape, num_classes, act='relu'):\n",
    "\n",
    "    # Input\n",
    "    x = Input(name='inputs', shape=features_shape, dtype='float32')\n",
    "    o = x\n",
    "    \n",
    "    # Flatten\n",
    "    o = Flatten(name='flatten')(o)\n",
    "    \n",
    "    # Dense layer\n",
    "    o = Dense(512, activation=act, name='dense1')(o)\n",
    "    o = Dense(512, activation=act, name='dense2')(o)\n",
    "    o = Dense(512, activation=act, name='dense3')(o)\n",
    "    \n",
    "    # Predictions\n",
    "    o = Dense(num_classes, activation='softmax', name='pred')(o)\n",
    "    \n",
    "    # Print network summary\n",
    "    Model(inputs=x, outputs=o).summary()\n",
    "    \n",
    "    return Model(inputs=x, outputs=o)\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization \n",
    " \n",
    "def deep_cnn(features_shape, num_classes, act='relu'):\n",
    " \n",
    "    x = Input(name='inputs', shape=features_shape, dtype='float32')\n",
    "    o = x\n",
    "    \n",
    "    # Block 1\n",
    "    o = Conv2D(32, (3, 3), activation=act, padding='same', strides=1, name='block1_conv', input_shape=features_shape)(o)\n",
    "    o = MaxPooling2D((3, 3), strides=(2,2), padding='same', name='block1_pool')(o)\n",
    "    o = BatchNormalization(name='block1_norm')(o)\n",
    "    \n",
    "    # Block 2\n",
    "    o = Conv2D(32, (3, 3), activation=act, padding='same', strides=1, name='block2_conv')(o)\n",
    "    o = MaxPooling2D((3, 3), strides=(2,2), padding='same', name='block2_pool')(o)\n",
    "    o = BatchNormalization(name='block2_norm')(o)\n",
    " \n",
    "    # Block 3\n",
    "    o = Conv2D(32, (3, 3), activation=act, padding='same', strides=1, name='block3_conv')(o)\n",
    "    o = MaxPooling2D((3, 3), strides=(2,2), padding='same', name='block3_pool')(o)\n",
    "    o = BatchNormalization(name='block3_norm')(o)\n",
    " \n",
    "    # Flatten\n",
    "    o = Flatten(name='flatten')(o)\n",
    "    \n",
    "    # Dense layer\n",
    "    o = Dense(64, activation=act, name='dense')(o)\n",
    "    o = BatchNormalization(name='dense_norm')(o)\n",
    "    o = Dropout(0.2, name='dropout')(o)\n",
    "    \n",
    "    # Predictions\n",
    "    o = Dense(num_classes, activation='softmax', name='pred')(o)\n",
    " \n",
    "    # Print network summary\n",
    "    Model(inputs=x, outputs=o).summary()\n",
    "    \n",
    "    return Model(inputs=x, outputs=o)\n",
    "\n",
    "\n",
    "model = deep_cnn(INPUT_SHAPE, NUM_CLASSES)\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "64/64 [==============================] - 7s 105ms/step - loss: 1.3917 - acc: 0.1406 - val_loss: 8.0607 - val_acc: 0.5000\n",
      "Epoch 2/15\n",
      "64/64 [==============================] - 2s 31ms/step - loss: 1.3898 - acc: 0.1719 - val_loss: 8.0659 - val_acc: 0.5000\n",
      "Epoch 3/15\n",
      "64/64 [==============================] - 2s 31ms/step - loss: 1.3891 - acc: 0.2188 - val_loss: 11.2065 - val_acc: 0.2500\n",
      "Epoch 4/15\n",
      "64/64 [==============================] - 2s 32ms/step - loss: 1.3874 - acc: 0.2500 - val_loss: 8.4868 - val_acc: 0.3750\n",
      "Epoch 5/15\n",
      "64/64 [==============================] - 2s 32ms/step - loss: 1.3881 - acc: 0.2188 - val_loss: 8.7107 - val_acc: 0.3750\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = [EarlyStopping(monitor='val_acc', patience=4, verbose=1, mode='max')]\n",
    " \n",
    "history = model.fit_generator(generator=dsGen.generator(BATCH, mode='train'),\n",
    "                              steps_per_epoch=int(np.ceil(len(dsGen.df_train)/BATCH)),\n",
    "                              epochs=EPOCHS,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=dsGen.generator(BATCH, mode='val'),\n",
    "                              validation_steps=int(np.ceil(len(dsGen.df_val)/BATCH)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n",
      "exporting D:/college/TRF/LEVEL-II/Task_3/chunk0.wav\n",
      "exporting D:/college/TRF/LEVEL-II/Task_3/chunk1.wav\n",
      "47104\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reading audio from user\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16 #paInt8\n",
    "CHANNELS = 1\n",
    "RATE = 16000 #sample rate\n",
    "RECORD_SECONDS = 3\n",
    "WAVE_OUTPUT_FILENAME = \"D:/college/TRF/LEVEL-II/Task_3/on/new.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK) #buffer\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "#print(int(RATE / CHUNK * RECORD_SECONDS))\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data) # 2 bytes(16 bits) per channel\n",
    "\n",
    "print(\"* done recording\")\n",
    "#print(frames)\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "#end of reading audio\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "threshold_freq=5500 \n",
    "eps=1e-10\n",
    "wav = (read(WAVE_OUTPUT_FILENAME))[1]\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play \n",
    "audio = AudioSegment.from_wav(WAVE_OUTPUT_FILENAME)\n",
    "play(audio)\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "sound_file = AudioSegment.from_wav(WAVE_OUTPUT_FILENAME)\n",
    "audio_chunks = split_on_silence(sound_file, \n",
    "    # must be silent for at least half a second\n",
    "    min_silence_len=100,\n",
    "\n",
    "    # consider it silent if quieter than -16 dBFS\n",
    "    silence_thresh=-20\n",
    ")\n",
    "count = 0\n",
    "for i, chunk in enumerate(audio_chunks):\n",
    "\n",
    "    out_file = \"D:/college/TRF/LEVEL-II/Task_3/chunk{0}.wav\".format(i)\n",
    "    print (\"exporting\", out_file)\n",
    "    chunk.export(out_file, format=\"wav\")\n",
    "    count += 1\n",
    "\n",
    "# Sample rate\n",
    "L = 16000\n",
    "print(len(wav))\n",
    "# If longer then randomly truncate\n",
    "if len(wav) > L:\n",
    "    i = np.random.randint(0, len(wav) - L)\n",
    "    wav = wav[i:(i+L)]  \n",
    "    print(len(wav))\n",
    "# If shorter then randomly add silence\n",
    "elif len(wav) < L:\n",
    "    rem_len = L - len(wav)\n",
    "    silence_part = np.random.randint(-100,100,16000).astype(np.float32) / np.iinfo(np.int16).max\n",
    "    j = np.random.randint(0, rem_len)\n",
    "    silence_part_left  = silence_part[0:j]\n",
    "    silence_part_right = silence_part[j:rem_len]\n",
    "    print(len(silence_part_left),\" \",len(wav),\" \",len(silence_part_right))\n",
    "    wav = np.concatenate([silence_part_left, wav, silence_part_right])\n",
    "# Create spectrogram using discrete FFT (change basis to frequencies)\n",
    "freqs, times, spec = stft(wav, L, nperseg = 400, noverlap = 240, nfft = 512, padded = False, boundary = None)\n",
    "# Cut high frequencies\n",
    "if threshold_freq is not None:\n",
    "    spec = spec[freqs <= threshold_freq,:]\n",
    "    freqs = freqs[freqs <= threshold_freq]\n",
    "    \n",
    "\n",
    "import pandas as pd\n",
    "e = \"on/new.wav\"\n",
    "    \n",
    "label, name = e.split('/')\n",
    "label_id = dsGen.text_to_labels(label)\n",
    "for j in range(count):\n",
    "    fle = \"D:/college/TRF/LEVEL-II/Task_3/chunk{0}.wav\".format(j)\n",
    "    sample = (label, label_id, name, fle)\n",
    "    n_df = pd.DataFrame(data = [sample],columns = ['label', 'label_id', 'user_id', 'wav_file'])\n",
    "    dsGen.df_test = dsGen.df_test.append(n_df)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsGen.df_test = dsGen.df_test[-count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label  label_id  user_id                                   wav_file\n",
      "0    on         2  new.wav  D:/college/TRF/LEVEL-II/Task_3/chunk0.wav\n",
      "0    on         2  new.wav  D:/college/TRF/LEVEL-II/Task_3/chunk1.wav\n"
     ]
    }
   ],
   "source": [
    "print(dsGen.df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step\n",
      "[0 2]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_generator(dsGen.generator(BATCH, mode='test'), \n",
    "                                     int(np.ceil(len(dsGen.df_test)/BATCH)), \n",
    "                                     verbose=1)\n",
    "\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "y_true = dsGen.df_test['label_id'].values\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Said: \n",
      "on bed "
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "print(\"You Said: \")\n",
    "for j in range(count):\n",
    "    ans.append(dsGen.labels_to_text(y_pred[len(dsGen.df_test) - 1 - j]))\n",
    "    print(ans[j],end = \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
